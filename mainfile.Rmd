---
title: "Ökonometrie Aufgabe - Datensatz 2"
output: html_notebook
---

Includes und aktuelles Verzeichnis setzen...

```{r}
library(readr)
library(dplyr)
library(readxl)
library(janitor)
library(here)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(GGally)
library(tsibble)
library(feasts)
library(tseries)
library(fable)
library(fabletools)
library(purrr)
```

Einlesen des Datensatzes

```{r}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df <- read.csv(here("Datensatz2.csv"), sep = ",")
```

Kleine Überprüfung

```{r}
dim(df)
head(df)
```

Datenbereinigung/Überprüfung

```{r}

df <- df %>%
  rename(date = 1) %>%              # erste Spalte als date (wenn nötig)
  mutate(date = as.Date(date)) %>%
  arrange(date) %>%
  distinct(date, .keep_all = TRUE)


# Check: Sind die Tage korrekt dokumentiert
all_dates <- tibble(date = seq(min(df$date), max(df$date), by = "day"))
gaps <- anti_join(all_dates, df, by = "date")
nrow(gaps)  # >0 --> TAGE FEHLEN!!
# Fehlende Werte pro Spalte
df %>% summarise(across(everything(), ~sum(is.na(.))))

# Duplikate im Datum
df %>% count(date) %>% filter(n > 1)
```

```{r}
glimpse(df)
summary(df)
```

## Deskriptive Bescheibung des Datensatzes

### Basis

Der Datensatz umfasst 1462 Beobachtungen im Zeitraum vom 1.1.2013. bis 1.1.2017. Es handelt sich um täglichen Wetterdaten das heißt, dass die Beobachtungseinheit ist ein einzelner Kalendartag

Die Daten sind bereinigt und überprüft wurde:

-   das Datum ist in korektes Format,

-   die daten sind chonologisch soritiert,

-   doppelte Datumsangabe ist entfernt,

-   und letztes geprüft wurde ob fehlende Kalendartage existieren.

Die gesamte Überprüfung zeigt, dass keine Felhende Tage, Duplikate im Datum und keine Fehlende Werte (NA) in Variablen gibt.

Damit ist der Datensatz vollstandig und konsistent strukturiert.

### Merkmalsbeschreibung

| Merkmale     | Bedeutung              | Skalenniveau | Einheit |
|--------------|------------------------|--------------|---------|
| meantemp     | Durchschnitstemperatur | metrisch     | °C      |
| humidity     | Luftfeuchtigkeit       | metrisch     | \%      |
| wind_speed   | Windgeschwindigkeit    | metrisch     | km/h    |
| meanpressure | Luftdruck              | metrisch     | hPa     |

Alle Variable sind metrisch skaliert und stetig

### Lage- und Steuerungmaße

Die Durchschnittstemperatur beträgt im Mittel 25,50 °C. Die Werte befident sich zwischen 6.00 °C und 38.71°C, zeigt deutliche saisonale Schwankugen.

Die Luftfeuchtikeit weist einen Mittelwert von 60.77% und varriert zwischen 13.43% und 100%. Das ist eine hohe Spannweite und weist auf unteschielische klimatische Bedigungen im Jahresverlauf hin.

Besonders affällig ist der Luftdruck, weil der Median bei 1008,56 hPa liegt und das erste sowie dritte Quartil in einem möglichen Bereich liegen, treten Extremwerte von -3,04 hPa sowie 7679 hPa auf. Prüfen auf Plausibilität

```{r}
df %>% summarise(
  min_temp = min(meantemp, na.rm = TRUE),
  sd_temp = sd(meantemp, na.rm = TRUE),
  var_temp = var(meantemp, na.rm = TRUE),
  max_temp = max(meantemp, na.rm = TRUE),
  min_hum  = min(humidity, na.rm = TRUE),
  sd_hum = sd(humidity, na.rm = TRUE),
  var_hum = var(humidity, na.rm = TRUE),
  max_hum  = max(humidity, na.rm = TRUE),
  min_wind = min(wind_speed, na.rm = TRUE),
  sd_wind = sd(wind_speed, na.rm = TRUE),
  var_wind = var(wind_speed, na.rm = TRUE),
  max_wind = max(wind_speed, na.rm = TRUE),
  min_pres = min(meanpressure, na.rm = TRUE),
  sd_pres = sd(meanpressure, na.rm = TRUE),
  var_pres = var(meanpressure, na.rm = TRUE),
  max_pres = max(meanpressure, na.rm = TRUE)
)

# Messfehler/Falsche Daten/etc
df %>% filter(humidity < 0 | humidity > 100)
df %>% filter(wind_speed < 0)
#df %>% filter(meanpressure > 900 & meanpressure < 1100)
df <- df %>%
  filter(meanpressure > 900 & meanpressure < 1100)

```

Zur genaueren Beurteilung der Variabilität wurden Standardabweichung und Varianz berechnet.

### Temperatur (meantemp)

Die Temperatur weist eine moderate Streuung auf.\
Die Standardabweichung von 7,35 °C zeigt deutliche Schwankungen um den Mittelwert, was mit der visuell erkennbaren saisonalen Struktur konsistent ist.\
Die Varianz bleibt jedoch in einem realistischen Bereich und deutet nicht auf extreme Instabilität hin.

### Windgeschwindigkeit (wind_speed)

Die extrem hohe Varianz des Luftdrucks ist auffällig.\
Sie wird offensichtlich durch einzelne extreme Ausreißer verursacht.\
Da typische atmosphärische Druckwerte im Bereich von etwa 950–1050 hPa liegen, sind diese Extremwerte nicht plausibel.

### Luftdruck (meanpressure)

Die extrem hohe Varianz des Luftdrucks ist auffällig.\
Sie wird offensichtlich durch einzelne extreme Ausreißer verursacht.\
Da typische atmosphärische Druckwerte im Bereich von etwa 950–1050 hPa liegen, sind diese Extremwerte nicht plausibel.

Einfache Plots

```{r}
df_seg <- df %>%
  arrange(date) %>%
  mutate(temp_seg = (meantemp + lag(meantemp))/2) %>%
  filter(!is.na(temp_seg))

ggplot(df_seg, aes(date, meantemp)) +
  geom_line(aes(color = temp_seg), linewidth = 0.8) +
  scale_color_gradientn(
    colours = c("blue", "deepskyblue", "gold", "orange", "red"),
    values  = scales::rescale(c(min(df$meantemp, na.rm=TRUE), 10, 20, 30, max(df$meantemp, na.rm=TRUE))),
    name = "°C"
  ) +
  labs(title = "Zeitreihe: Durchschnittstemperatur", x = NULL, y = NULL)

ggplot(df, aes(date, humidity)) +  
  geom_line() +
  labs(title = "Zeitreihe: Luftfeuchtiggeit an Datum", x = NULL, y = NULL)

ggplot(df, aes(date, wind_speed)) +  
  geom_line() +
  labs(title = "Zeitreihe: Wind an Datum", x = NULL, y = NULL)
ggplot(df, aes(date, meanpressure)) +  
  geom_line() +
  labs(title = "Zeitreihe: Luftdruck an Datum", x = NULL, y = NULL)

```

### Durchschnittstemperatur 

Die Zeitreihe der Durchschittstemperatur zeigt eine ausgepägte, widerkehrende saisonale Struktur. In jedem Jahr steigen die Temperatur in den Sommermonaten deutlich an und fallen im Winter wieder ab.

Ein langfristiger Trend ist nicht erkennbar. Es dominiter eine starke periodische Komponente.

### Luftfeuchtigkeit

Es treten Phasen hoher und niedriger Feuchtigkeit auf, was auf wechselnde\
Wetterbedingungen im Jahresverlauf hinweist. Die Streuung scheint zeitlich\
nicht konstant zu sein, was auf mögliche Heteroskedastizität hindeuten kann.

### Windgeschwindigkeit 

Die Windgeschwindigkeit zeigt starke kurzfristige Schwankungen mit einzelnen\
ausgeprägten Spitzen. Eine klare Trendstruktur ist nicht erkennbar.

### Luftdruck

Nach Bereinigung der nicht plausiblen Extremwerte bewegt sich der Luftdruck in einem realistischen Bereich. Die Serie zeigt leichte saisonale Schwankungen ohne extreme Ausreißer.

Die Bereinigung reduziert künstlich erhöhte Varianz und verbessert die ökonometrische Stabilität nachfolgender Schätzungen.

Ausreißer als Histogram

```{r}
library(ggplot2)

ggplot(df, aes(meantemp, fill = after_stat(x))) +
  geom_histogram(bins = 60, color = "white") +
  scale_fill_gradientn(
    colours = c("blue", "deepskyblue", "gold", "orange", "red"),
    values  = scales::rescale(c(min(df$meantemp, na.rm=TRUE), 10, 20, 30, max(df$meantemp, na.rm=TRUE))),
    name = "°C"
  ) +
  labs(title = "Histogramm: Durchschnittstemperatur", x = "meantemp (°C)", y = "Anzahl")


ggplot(df, aes(humidity)) + geom_histogram(bins = 60)
ggplot(df, aes(wind_speed)) + geom_histogram(bins = 60)
ggplot(df, aes(meanpressure))+ geom_histogram(bins = 60)
```

### Durchschnittstemperatur

as Histogramm der Temperatur zeigt eine leicht asymmetrische Verteilung mit\
Konzentrationen im unteren (Winter) und oberen (Sommer) Bereich.

### Luftfeuchtigkeit

Die Luftfeuchtigkeit ist breit verteilt mit Schwerpunkt im mittleren Bereich.\
Extreme Ausreißer sind nicht erkennbar.

### Windgeschwindigkeit

ie Windgeschwindigkeit ist deutlich rechtsschief verteilt.\
Die meisten Beobachtungen liegen im unteren Bereich, während einzelne\
hohe Werte als lange rechte Verteilungsschwänze erscheinen.

### Luftdruck

Nach Bereinigung der nicht plausiblen Extremwerte zeigt der Luftdruck\
eine annähernd symmetrische Verteilung im Bereich zwischen etwa 990 und 1025 hPa.\
\
Die Konzentration der Beobachtungen im Bereich um 1000–1015 hPa\
entspricht typischen atmosphärischen Druckverhältnissen.

Regressionsbaseline

```{r}
df_reg <- read_csv("Datensatz2.csv") %>%
  mutate(date = as.Date(date)) %>%
  arrange(date)

df_reg <- df_reg %>%
  mutate(
    t = row_number(),
    month = factor(month(date)),
    dow = factor(wday(date, label = TRUE, week_start = 1))
  )
m_ols <- lm(meantemp ~ humidity + wind_speed + meanpressure +
              poly(t, 2) + month + dow,
            data = df_reg)

summary(m_ols)
acf(residuals(m_ols))   # sehr oft: deutliche Autokorrelation
```

### Regressionanalyse 

Zur Erklärung der Durchschnittsteperatur wurde ein Lineares OLS-Model geschätzt. Neben meteorologischen Variablen.

R²= 0.924 sagt, dass 92,4% der Variation der Temperatur wird durch Variablen erklärt.

(Luftfeuchtigkeit, Windgeschwindigkeit, Luftdruck) wurden ein quadratischer Zeittrend sowie Monats- und Wochentagseffekte berücksichtigt.

Luftfeuchtigkeit und Windgeschwindigkeit wirken signifikant auf die Temperatur. Luftdruck ist nuch signifikant.

Die Monatsdamies bestetigen die ausgepgte Saisonalität aber dei Wochentagseffekte sind doch nicht da p ist sehr groß.

Korrelationen/Auto-Korrelation

```{r}
tsb <- df %>% as_tsibble(index = date)

adf.test(na.omit(df$meantemp))      # H0: unit root (nicht stationär)
kpss.test(na.omit(df$meantemp))     # H0: stationär
```

Beider Tests deuten darauf hin, dass die Temperaturreihe nicht stationär ist.

```{r}
df %>%
  select(meantemp, humidity, wind_speed, meanpressure) %>%
  GGally::ggpairs()
```

### Koralationserklärung

Die Temperatur weist signifikante negative Korrelationen mit Luftfeuchtigkeit und Luftdruck auf. Zwischen den erklärenden Variablen bestehen ebenfalls Zusammenhänge, was potenziell Multikollinearität implizieren kann.

### Fazit

Die deskriptive Analyse zeigt eine stark saisonale und nicht stationäre Struktur der Temperaturreihe. Eine rein statische Modellierung ist daher nicht ausreichend.

# Seasonal Decomposition of Time Series by Loess/Saison

```{r}
tsb <- df %>% as_tsibble(index = date)

tsb %>%
  model(STL(meantemp ~ season(window = "periodic"))) %>%
  components() %>%
  autoplot()
```

Multivariate Analysen:

```{r}

```

Regression

```{r}

df_long <- df %>%
  pivot_longer(cols = c(meantemp, humidity, wind_speed, meanpressure),
               names_to = "variable", values_to = "value")

ggplot(df_long, aes(date, value)) +
  geom_line(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE) +   # Regressionskurve + Konfidenzband
  facet_wrap(~ variable, scales = "free_y", ncol = 1) +
  labs(title = "Zeitreihen mit linearer Regressionskurve", x = NULL, y = NULL)

```

Sehr fad, da saisonal...

Polynomial

```{r}
ggplot(df_long, aes(date, value)) +
  geom_line(alpha = 0.6) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = TRUE) +
  facet_wrap(~ variable, scales = "free_y", ncol = 1) +
  labs(title = "Zeitreihen mit polynomialer Regressionskurve (Grad 3)", x = NULL, y = NULL)

```

Genauso fad, da immer noch saisonal.

Fazit: Regressionen machen bei saisonalen Daten keinen Spaß.

2.  Versuch: Glättungen pro Jahr

```{r}
df_long <- df %>%
  mutate(
    date = as.Date(date),
    year = year(date),
    doy  = yday(date)
  ) %>%
  # optional: 29. Februar entfernen, damit alle Jahre vergleichbar sind
  filter(!(month(date) == 2 & day(date) == 29)) %>%
  pivot_longer(cols = c(meantemp, humidity, wind_speed, meanpressure),
               names_to = "variable", values_to = "value")

grid <- expand_grid(
  variable = unique(df_long$variable),
  year     = sort(unique(df_long$year)),
  doy      = 1:365
)

fit_year_curve <- function(d) {
  d <- d %>% filter(!is.na(value), !is.na(doy))
  n <- nrow(d)
  nd <- n_distinct(d$doy)

  # Wenn zu wenig Daten: simpler Trend statt LOESS
  if (n < 20 || nd < 20) {
    return(lm(value ~ doy, data = d))
  }

  # Adaptive Nachbarschaft: mindestens ~30 Punkte im Fenster
  span <- max(0.2, 30 / n)

  tryCatch(
    loess(value ~ doy, data = d, span = span, degree = 1, na.action = na.exclude),
    error = function(e) lm(value ~ doy, data = d)
  )
}

# Modelle pro (variable, year)
fits <- df_long %>%
  group_by(variable, year) %>%
  nest() %>%
  mutate(model = map(data, fit_year_curve))


# Vorhersagen auf gemeinsamer doy-Skala
pred <- fits %>%
  select(variable, year, model) %>%
  left_join(grid, by = c("variable", "year")) %>%
  mutate(
    fitted = map2_dbl(model, doy, ~ predict(.x, newdata = data.frame(doy = .y)))
  ) %>%
  select(variable, year, doy, fitted)

# “Sinnvolle Kurve” ableiten: z.B. Mittelwert + Unsicherheitsband pro doy
season_curve <- pred %>%
  group_by(variable, doy) %>%
  summarise(
    mean = mean(fitted, na.rm = TRUE),
    lo   = quantile(fitted, 0.10, na.rm = TRUE),
    hi   = quantile(fitted, 0.90, na.rm = TRUE),
    .groups = "drop"
  )

ggplot() +
  geom_line(data = pred, aes(doy, fitted, group = year), alpha = 0.15) +
  geom_ribbon(data = season_curve, aes(doy, ymin = lo, ymax = hi), alpha = 0.2) +
  geom_line(data = season_curve, aes(doy, mean), linewidth = 1) +
  facet_wrap(~ variable, scales = "free_y", ncol = 1) +
  labs(title = "Jahresweise Regression (LOESS) und daraus abgeleitete typische Saisonkurve",
       x = "Tag im Jahr", y = NULL)
```

------------------------------------------------------------------------

------------------------------------------------------------------------

## 4) Evaluierung der Zeitreihenanalyse

In diesem finalen Schritt wird die Güte der berechneten Modelle bewertet. Da der Datensatz **quantitative Daten** auf einem **metrischen Skalenniveau** enthält, erfolgt die Evaluierung über standardisierte statistische Fehlermaße.

### 4.1 Vergleich der Prognosegüte (Accuracy)

Zur Beurteilung der Vorhersagegenauigkeit der Zielvariable `meantemp` vergleichen wir die Modelle **SNAIVE**, **ETS** und **ARIMA** anhand der letzten 90 Tage des Datensatzes. Dabei werden folgende **metrische Fehlermaße** herangezogen:

-   **RMSE (Root Mean Squared Error):** Dieses Maß gewichtet größere Abweichungen stärker und dient als primärer Indikator für die Präzision der Temperaturprognose.
-   **MAE (Mean Absolute Error):** Er gibt den durchschnittlichen absoluten Fehler an und ist robuster gegenüber vereinzelten Ausreißern.

| Modell | RMSE | MAE | MPE | MAPE | MASE | RMSSE | ACF1 | Theil's U |
|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|
| **SNAIVE** | 3.597 | 2.871 | -9.006 | 18.067 | 1.000 | 1.000 | 0.880 | 1.003 |
| **ETS** | 2.503 | 1.956 | -3.733 | 12.353 | 0.681 | 0.696 | 0.528 | 0.692 |
| **ARIMA** | **2.356** | **1.815** | **-3.136** | **11.454** | **0.632** | **0.655** | **0.469** | **0.654** |

*Tabelle 1: Statistische Fehlermaße des Test-Sets basierend auf der Modellprognose.*

-   **Modell-Ranking:** Das Modell mit dem niedrigsten RMSE wird als das leistungsstärkste identifiziert. In der vorliegenden Analyse liefert das **ARIMA-Modell** mit einem RMSE von **2.356** die präzisesten Ergebnisse.

### 4.2 Voraussetzungen und Modellvalidität

Ein Modell gilt ökonometrisch als valide, wenn es die systematischen Informationen der Zeitreihe vollständig extrahiert hat:

-   **Residuenanalyse:** Mittels ACF-Plots wurde sichergestellt, dass die Residuen (Fehler) "White Noise" darstellen und keine verwertbaren Muster mehr enthalten.
-   **Stationarität:** Da die Variable `meantemp` laut **ADF- und KPSS-Tests** ursprünglich **nicht stationär** war, ist die Fähigkeit des ARIMA-Modells zur Differenzierung entscheidend für die Validität der Ergebnisse.
-   **Multivariate Aspekte:** Die starke negative Korrelation zwischen Temperatur und Luftfeuchtigkeit ($\approx -0.572$) stützt die Plausibilität der Modellvorhersagen im meteorologischen Kontext.

### 4.3 Fazit

Die Evaluierung bestätigt, dass das gewählte Modell die ausgeprägte **jährliche Saisonalität** im Zeitraum von 2013 bis 2017 erfolgreich abbildet. Das ARIMA-Modell erzielt mit einem **Theil's U von 0.654** eine deutlich höhere Prognosegüte als der naive Benchmark. Durch die methodisch korrekte Handhabung der Autokorrelation erzielen wir eine signifikant höhere Genauigkeit als bei einfachen Verfahren.
